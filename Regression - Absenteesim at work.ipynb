{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Absenteesim at work dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A linear regression is used herein for estimating the number of hours a person would be absent from work given their available information. For this, we use the \"absenteesim at work\" dataset obtained from the UCI repository, which could be find in the repository. In the dataset, you can find information about individuals, such as their age, education, reasons for absence, etc., as well as the target variable, which is absenteesim time in hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to check how many data points does the dataset includes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Absenteeism_at_work.csv', sep=',')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we randomly split the data into train and test with the ratio 80/20, that is, use 80% of the data to fit the line, and the remaining 20% for testing, with the pre-specified random seed. We train a linear regression model on the training data. Then, we use the trained model to estimate hours of absence in the test data. Finally the average root mean squared error (RMSE) on the test data is reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting independent variables\n",
    "X = data.iloc[:, :-1].values\n",
    "# setting the dependent variable\n",
    "Y = data.iloc[:, 20].values\n",
    "# splitting the data into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an object of the LinearRegression class\n",
    "regressor = LinearRegression()\n",
    "# now fitting the regressor to the training set (training a linear regression model on the training data)\n",
    "regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the hours of absence using our test set\n",
    "Y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.88834873358575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# calculating the RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this number indicates how deviated is our predicted Y from the actual Y. 8 is a high deviation, this means the trained model isn't good enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform 10-fold cross validation and report the RMSE obtained from each fold as well as their average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round  1\n",
      "RMSE: 8.651021549609844\n",
      "Round  2\n",
      "RMSE: 9.03591145893391\n",
      "Round  3\n",
      "RMSE: 9.420931511576645\n",
      "Round  4\n",
      "RMSE: 16.180963120973963\n",
      "Round  5\n",
      "RMSE: 17.73145509695458\n",
      "Round  6\n",
      "RMSE: 13.625950590726045\n",
      "Round  7\n",
      "RMSE: 13.017003764095728\n",
      "Round  8\n",
      "RMSE: 7.67165572270588\n",
      "Round  9\n",
      "RMSE: 17.58268462081495\n",
      "Round  10\n",
      "RMSE: 8.423446713220475\n",
      "12.134102414961202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle= True,random_state=1234)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "sum_rmse = []\n",
    "j =1\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X, Y)):\n",
    "    print ('Round ', j)\n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    regressor.fit(X_train, Y_train)\n",
    "    Y_pred = regressor.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "    print('RMSE:', rmse)\n",
    "    sum_rmse.append(rmse)\n",
    "    j += 1\n",
    "    \n",
    "average = sum(sum_rmse)/len(sum_rmse)\n",
    "print(average)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the average rsme in the 10-fold is higher than the rsme of the simple train-test. This means that in average the k-fold cross validation method produces a more deviated Y compared to actual Y. Based on this analysis, it suffice to use cross-validation and don't simply train and test with a random split of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This time, we are interested in K neighbors regression instead of a regression on the whole dataset and we would like to analyze what would be reasonable number of neighbors and what distance to use based on the data. To do so, we're performing a 10-fold cross validation. In each fold, we fit a “weighted” linear regression in the following manner: For a given test data point, we would like to estimate its outcome based on its k ∈ {1, . . . , 10} nearest neighbors and a regression line weighted by the inverse of the distance of the neighbors of the test point. We use the Minkowski distance with degree p ∈ {1, . . . , 10}. For each fold, the k and p at which we obtain the lowest RMSE is reported as well as the average RMSE across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  1\n",
      "Minimum RMSE at fold number  1  equals to  11.462162935258915\n",
      "[(9, 3)]  showing number of neighbors and Minkowski degree respectfully\n",
      " \n",
      "FOLD  2\n",
      "Minimum RMSE at fold number  2  equals to  9.78884794294491\n",
      "[(2, 0)]  showing number of neighbors and Minkowski degree respectfully\n",
      " \n",
      "FOLD  3\n",
      "Minimum RMSE at fold number  3  equals to  9.820543712298065\n",
      "[(9, 0)]  showing number of neighbors and Minkowski degree respectfully\n",
      " \n",
      "FOLD  4\n",
      "Minimum RMSE at fold number  4  equals to  19.602918258422726\n",
      "[(9, 6)]  showing number of neighbors and Minkowski degree respectfully\n",
      " \n",
      "FOLD  5\n",
      "Minimum RMSE at fold number  5  equals to  18.028951440770513\n",
      "[(1, 0)]  showing number of neighbors and Minkowski degree respectfully\n",
      " \n",
      "FOLD  6\n",
      "Minimum RMSE at fold number  6  equals to  12.76236460588745\n",
      "[(4, 0)]  showing number of neighbors and Minkowski degree respectfully\n",
      " \n",
      "FOLD  7\n",
      "Minimum RMSE at fold number  7  equals to  14.403158770080491\n",
      "[(8, 3)]  showing number of neighbors and Minkowski degree respectfully\n",
      " \n",
      "FOLD  8\n",
      "Minimum RMSE at fold number  8  equals to  10.372679547945118\n",
      "[(9, 7)]  showing number of neighbors and Minkowski degree respectfully\n",
      " \n",
      "FOLD  9\n",
      "Minimum RMSE at fold number  9  equals to  18.46842069307234\n",
      "[(9, 8)]  showing number of neighbors and Minkowski degree respectfully\n",
      " \n",
      "FOLD  10\n",
      "Minimum RMSE at fold number  10  equals to  8.031463168749033\n",
      "[(5, 0)]  showing number of neighbors and Minkowski degree respectfully\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.read_csv('Absenteeism_at_work.csv', sep=',')\n",
    "X = data.iloc[:, :-1].values\n",
    "# setting the dependent variable\n",
    "Y = data.iloc[:, 20].values\n",
    "# splitting the data into train and test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1234)\n",
    "\n",
    "#creating a list of K for KNN\n",
    "neighbors = list(range(1,11))\n",
    "degree = list(range(1,11))\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=True, random_state=1234)\n",
    "\n",
    "#this is a definition adopted from https://stackoverflow.com/questions/8189169/nested-lists-python for flattening list of lists\n",
    "def flatten(lists):\n",
    "  results = []\n",
    "  for numbers in lists:\n",
    "    for numbers2 in numbers:\n",
    "        results.append(numbers2) \n",
    "  return results\n",
    "\n",
    "        \n",
    "j =1 \n",
    "for i, (train_index, test_index) in enumerate(kf.split(X, Y)):\n",
    "    print ('FOLD ', j)\n",
    "    x_train, x_test, y_train, y_test = X[train_index], X[test_index], Y[train_index], Y[test_index] \n",
    "    ALL=[]\n",
    "    for k in neighbors:\n",
    "        #print ('Number of neighbors: ', k)\n",
    "        RMSE = [] \n",
    "        for p in degree:\n",
    "            #print ('    ','Minkowski degree: ', p)\n",
    "            knn = KNeighborsRegressor(n_neighbors=k, weights='distance', p = p, metric='minkowski')\n",
    "            knn.fit(x_train, y_train)\n",
    "            y_pred = knn.predict(x_test)\n",
    "            # calculating the RMSE\n",
    "            rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "            #print('     ', 'RMSE: ', rmse)\n",
    "            RMSE.append(rmse)\n",
    "\n",
    "        #print('MINIMUM RMSE', RMSE)\n",
    "        ALL.append(RMSE)\n",
    "        \n",
    "    MIN_RMSE= min(min(ALL))\n",
    "    print('Minimum RMSE at fold number ', j,' equals to ', MIN_RMSE)\n",
    "    #this is to find index of MIN_RMSE in a list of lists\n",
    "    print([(k, ALL.index(MIN_RMSE))\n",
    " for k, ALL in enumerate(ALL)\n",
    " if MIN_RMSE in ALL], \" showing number of neighbors and Minkowski degree respectfully\")\n",
    "    print(' ')\n",
    "    j += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE RMSE ACROSS ALL FOLDS:  8.97591200823197\n"
     ]
    }
   ],
   "source": [
    "print('AVERAGE RMSE ACROSS ALL FOLDS: ', sum(flatten(ALL))/len(flatten(ALL)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this number indicates how deviated is our predicted Y from the actual Y. 8 is a high deviation, this means the trained model isn't good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
